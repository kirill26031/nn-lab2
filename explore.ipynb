{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import dataset, PlantOrgansDataset\n",
    "from preprocessing import preprocess_image_and_mask\n",
    "import torchvision.transforms.v2 as T\n",
    "import torch\n",
    "import numpy as np\n",
    "from alexnet import patch_index_to_position, image_to_patches, MyTransform\n",
    "import train\n",
    "from train import device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "commonTransform = T.Compose([\n",
    "        T.Resize(size=(2048, 2048)),\n",
    "        T.ToTensor()\n",
    "        \n",
    "        # T.RandomHorizontalFlip(p=0.5),\n",
    "        # T.RandomVerticalFlip(p=0.5),\n",
    "        # T.RandomRotation(degrees=45)\n",
    "    ])\n",
    "imagesTransform = T.Compose([\n",
    "    # T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    MyTransform(256),\n",
    "    T.Resize((224, 224)),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "masksTransform = T.Compose([\n",
    "    T.ToDtype(torch.float16),\n",
    "    # T.Normalize(mean=[0.0014], std=[0.0031]),\n",
    "    MyTransform(256),\n",
    "    # T.Resize((224, 224))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation_data = dataset['train'].train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = PlantOrgansDataset(train_validation_data['train'], commonTransform, imagesTransform, masksTransform)\n",
    "validation_dataset = PlantOrgansDataset(train_validation_data['test'], commonTransform, imagesTransform, masksTransform)\n",
    "test_dataset = PlantOrgansDataset(dataset['validation'], commonTransform, imagesTransform, masksTransform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset:  4596\n",
      "validation_dataset:  1149\n",
      "test_dataset:  1437\n"
     ]
    }
   ],
   "source": [
    "print(\"train_dataset: \", len(train_dataset))\n",
    "print(\"validation_dataset: \", len(validation_dataset))\n",
    "print(\"test_dataset: \", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedDataLoader:\n",
    "    def __init__(self, loader, func):\n",
    "        self.loader = loader\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.loader)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in iter(self.loader):\n",
    "            batch_cuda = []\n",
    "            for X, y, size in batch:\n",
    "                batch_cuda.append(self.func(X, y, size))\n",
    "            yield batch_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(X, y, size):\n",
    "    return X.to(device), y.to(device, dtype=torch.float16), size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    batchs_amount = len(batch)\n",
    "    current_images = []\n",
    "    current_masks = []\n",
    "    current_sizes = []\n",
    "    current_length = 0\n",
    "    for i in range(batchs_amount):\n",
    "        if current_length == batch_size:\n",
    "            yield torch.concatenate(current_images), torch.concatenate(current_masks)\n",
    "        else:    \n",
    "            images, masks, size = batch[i]\n",
    "            current_length += len(images)\n",
    "            current_images.append(images)\n",
    "            current_sizes.append(size)\n",
    "            current_masks.append(masks)\n",
    "    \n",
    "    # Split images and masks into groups of batch_size\n",
    "    image_splits = torch.split(images, batch_size, dim=0)  # Split into chunks of batch_size images\n",
    "    mask_splits = torch.split(masks, batch_size, dim=0)    # Split into chunks of batch_size masks\n",
    "    \n",
    "    # Return as a list of batches\n",
    "    for img_split, mask_split in zip(image_splits, mask_splits):\n",
    "        yield img_split, mask_split, size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = WrappedDataLoader(\n",
    "    DataLoader(train_dataset, batch_size=1, shuffle=False, collate_fn=custom_collate_fn, \n",
    "               pin_memory=True, pin_memory_device=[device]), to_device)\n",
    "valid_loader = WrappedDataLoader(\n",
    "    DataLoader(validation_dataset, batch_size=1, shuffle=False, collate_fn=custom_collate_fn,\n",
    "               pin_memory=True, pin_memory_device=[device]), to_device)\n",
    "test_loader = WrappedDataLoader(\n",
    "    DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=custom_collate_fn,\n",
    "               pin_memory=True, pin_memory_device=[device]), to_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\pc/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=False).to(device)\n",
    "\n",
    "model.classifier[6] = torch.nn.Linear(in_features=4096, out_features=4, bias=True).to(device)\n",
    "\n",
    "# model = AlexNet([11, 5, 3, 3, 3], [96, 256, 384, 384, 256], [0, 2, 1, 1, 1], [4096, 4096], 4, 224).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_image = T.ToPILImage()\n",
    "mask_to_image = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.ToDtype(torch.float16),\n",
    "    T.Normalize(mean=[0.0014], std=[0.0031]),\n",
    "    T.ToPILImage(),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1.3770631551742554 tensor(37.9652, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(len(batch))\n",
    "    for X, y, size in batch:\n",
    "        # print(X.shape)\n",
    "        predicted = model(X)\n",
    "        loss_, correct, _ = train.pixel_validate(model, torch.nn.CrossEntropyLoss(), X, y)\n",
    "        print(loss_, correct)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "tensors = []\n",
    "for batch in train_loader:\n",
    "    for X, y, size in batch:\n",
    "        for i in range(len(y)):\n",
    "            images.append(mask_to_image(y[i]))\n",
    "            tensors.append(y[i])\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0157, device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.concatenate(tensors, dim=1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_to_image(train_validation_data['train'][0]['label'])\n",
    "\n",
    "# mask_to_image(torch.concatenate(tensors, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate  1\n",
      "evaluate  2\n",
      "evaluate  3\n",
      "evaluate  4\n",
      "evaluate  5\n",
      "evaluate  6\n",
      "evaluate  7\n",
      "evaluate  8\n",
      "evaluate  9\n",
      "evaluate  10\n",
      "evaluate  11\n",
      "evaluate  12\n",
      "evaluate  13\n",
      "evaluate  14\n",
      "evaluate  15\n",
      "evaluate  16\n",
      "evaluate  17\n",
      "evaluate  18\n",
      "evaluate  19\n",
      "evaluate  20\n",
      "evaluate  21\n",
      "evaluate  22\n",
      "evaluate  23\n",
      "evaluate  24\n",
      "evaluate  25\n",
      "evaluate  26\n",
      "evaluate  27\n",
      "evaluate  28\n",
      "evaluate  29\n",
      "evaluate  30\n",
      "evaluate  31\n",
      "evaluate  32\n",
      "evaluate  33\n",
      "evaluate  34\n",
      "evaluate  35\n",
      "evaluate  36\n",
      "evaluate  37\n",
      "evaluate  38\n",
      "evaluate  39\n",
      "evaluate  40\n",
      "evaluate  41\n",
      "evaluate  42\n",
      "evaluate  43\n",
      "evaluate  44\n",
      "evaluate  45\n",
      "evaluate  46\n",
      "evaluate  47\n",
      "evaluate  48\n",
      "evaluate  49\n",
      "evaluate  50\n",
      "evaluate  51\n",
      "evaluate  52\n",
      "evaluate  53\n",
      "evaluate  54\n",
      "evaluate  55\n",
      "evaluate  56\n",
      "evaluate  57\n",
      "evaluate  58\n",
      "evaluate  59\n",
      "evaluate  60\n",
      "evaluate  61\n",
      "evaluate  62\n",
      "evaluate  63\n",
      "evaluate  64\n",
      "evaluate  65\n",
      "evaluate  66\n",
      "evaluate  67\n",
      "evaluate  68\n",
      "evaluate  69\n",
      "evaluate  70\n",
      "evaluate  71\n",
      "evaluate  72\n",
      "evaluate  73\n",
      "evaluate  74\n",
      "evaluate  75\n",
      "evaluate  76\n",
      "evaluate  77\n",
      "evaluate  78\n",
      "evaluate  79\n",
      "evaluate  80\n",
      "evaluate  81\n",
      "evaluate  82\n",
      "evaluate  83\n",
      "evaluate  84\n",
      "evaluate  85\n",
      "evaluate  86\n",
      "evaluate  87\n",
      "evaluate  88\n",
      "evaluate  89\n",
      "evaluate  90\n",
      "evaluate  91\n",
      "evaluate  92\n",
      "evaluate  93\n",
      "evaluate  94\n",
      "evaluate  95\n",
      "evaluate  96\n",
      "evaluate  97\n",
      "evaluate  98\n",
      "evaluate  99\n",
      "evaluate  100\n",
      "evaluate  101\n",
      "evaluate  102\n",
      "evaluate  103\n",
      "evaluate  104\n",
      "evaluate  105\n",
      "evaluate  106\n",
      "evaluate  107\n",
      "evaluate  108\n",
      "evaluate  109\n",
      "evaluate  110\n",
      "evaluate  111\n",
      "evaluate  112\n",
      "evaluate  113\n",
      "evaluate  114\n",
      "evaluate  115\n",
      "evaluate  116\n",
      "evaluate  117\n",
      "evaluate  118\n",
      "evaluate  119\n",
      "evaluate  120\n",
      "evaluate  121\n",
      "evaluate  122\n",
      "evaluate  123\n",
      "evaluate  124\n",
      "evaluate  125\n",
      "evaluate  126\n",
      "evaluate  127\n",
      "evaluate  128\n",
      "evaluate  129\n",
      "evaluate  130\n",
      "evaluate  131\n",
      "evaluate  132\n",
      "evaluate  133\n",
      "evaluate  134\n",
      "evaluate  135\n",
      "evaluate  136\n",
      "evaluate  137\n",
      "evaluate  138\n",
      "evaluate  139\n",
      "evaluate  140\n",
      "evaluate  141\n",
      "evaluate  142\n",
      "evaluate  143\n",
      "evaluate  144\n",
      "evaluate  145\n",
      "evaluate  146\n",
      "evaluate  147\n",
      "evaluate  148\n",
      "evaluate  149\n",
      "evaluate  150\n",
      "evaluate  151\n",
      "evaluate  152\n",
      "evaluate  153\n",
      "evaluate  154\n",
      "evaluate  155\n",
      "evaluate  156\n",
      "evaluate  157\n",
      "evaluate  158\n",
      "evaluate  159\n",
      "evaluate  160\n",
      "evaluate  161\n",
      "evaluate  162\n",
      "evaluate  163\n",
      "evaluate  164\n",
      "evaluate  165\n",
      "evaluate  166\n",
      "evaluate  167\n",
      "evaluate  168\n",
      "evaluate  169\n",
      "evaluate  170\n",
      "evaluate  171\n",
      "evaluate  172\n",
      "evaluate  173\n",
      "evaluate  174\n",
      "evaluate  175\n",
      "evaluate  176\n",
      "evaluate  177\n",
      "evaluate  178\n",
      "evaluate  179\n",
      "evaluate  180\n",
      "evaluate  181\n",
      "evaluate  182\n",
      "evaluate  183\n",
      "evaluate  184\n",
      "evaluate  185\n",
      "evaluate  186\n",
      "evaluate  187\n",
      "evaluate  188\n",
      "evaluate  189\n",
      "evaluate  190\n",
      "evaluate  191\n",
      "evaluate  192\n",
      "evaluate  193\n",
      "evaluate  194\n",
      "evaluate  195\n",
      "evaluate  196\n",
      "evaluate  197\n",
      "evaluate  198\n",
      "evaluate  199\n",
      "evaluate  200\n",
      "evaluate  201\n",
      "evaluate  202\n",
      "evaluate  203\n",
      "evaluate  204\n",
      "evaluate  205\n",
      "evaluate  206\n",
      "evaluate  207\n",
      "evaluate  208\n",
      "evaluate  209\n",
      "evaluate  210\n",
      "evaluate  211\n",
      "evaluate  212\n",
      "evaluate  213\n",
      "evaluate  214\n",
      "evaluate  215\n",
      "evaluate  216\n",
      "evaluate  217\n",
      "evaluate  218\n",
      "evaluate  219\n",
      "evaluate  220\n",
      "evaluate  221\n",
      "evaluate  222\n",
      "evaluate  223\n",
      "evaluate  224\n",
      "evaluate  225\n",
      "evaluate  226\n",
      "evaluate  227\n",
      "evaluate  228\n",
      "evaluate  229\n",
      "evaluate  230\n",
      "evaluate  231\n",
      "evaluate  232\n",
      "evaluate  233\n",
      "evaluate  234\n",
      "evaluate  235\n",
      "evaluate  236\n",
      "evaluate  237\n",
      "evaluate  238\n",
      "evaluate  239\n",
      "evaluate  240\n",
      "evaluate  241\n",
      "evaluate  242\n",
      "evaluate  243\n",
      "evaluate  244\n",
      "evaluate  245\n",
      "evaluate  246\n",
      "evaluate  247\n",
      "evaluate  248\n",
      "evaluate  249\n",
      "evaluate  250\n",
      "evaluate  251\n",
      "evaluate  252\n",
      "evaluate  253\n",
      "evaluate  254\n",
      "evaluate  255\n",
      "evaluate  256\n",
      "evaluate  257\n",
      "evaluate  258\n",
      "evaluate  259\n",
      "evaluate  260\n",
      "evaluate  261\n",
      "evaluate  262\n",
      "evaluate  263\n",
      "evaluate  264\n",
      "evaluate  265\n",
      "evaluate  266\n",
      "evaluate  267\n",
      "evaluate  268\n",
      "evaluate  269\n",
      "evaluate  270\n",
      "evaluate  271\n",
      "evaluate  272\n",
      "evaluate  273\n",
      "evaluate  274\n",
      "evaluate  275\n",
      "evaluate  276\n",
      "evaluate  277\n",
      "evaluate  278\n",
      "evaluate  279\n",
      "evaluate  280\n",
      "evaluate  281\n",
      "evaluate  282\n",
      "evaluate  283\n",
      "evaluate  284\n",
      "evaluate  285\n",
      "evaluate  286\n",
      "evaluate  287\n",
      "evaluate  288\n",
      "evaluate  289\n",
      "evaluate  290\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train\u001b[38;5;241m.\u001b[39mevaluate(model, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(), valid_loader)\n",
      "File \u001b[1;32mc:\\Users\\pc\\Documents\\repos\\mp-2\\nn\\nn-lab2\\train.py:57\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, loss_func, loader)\u001b[0m\n\u001b[0;32m     54\u001b[0m validated_batches \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     56\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m     58\u001b[0m   i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     59\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m X, y, _ \u001b[38;5;129;01min\u001b[39;00m batch:\n",
      "Cell \u001b[1;32mIn[22], line 10\u001b[0m, in \u001b[0;36mWrappedDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader):\n\u001b[0;32m     11\u001b[0m         batch_cuda \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m X, y, size \u001b[38;5;129;01min\u001b[39;00m batch:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\pc\\Documents\\repos\\mp-2\\nn\\nn-lab2\\data.py:90\u001b[0m, in \u001b[0;36mPlantOrgansDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m     89\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[index][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 90\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[index][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     91\u001b[0m     size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[index][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msize\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommon_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\arrow_dataset.py:2872\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2870\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[0;32m   2871\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem(key)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\arrow_dataset.py:2857\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[1;34m(self, key, **kwargs)\u001b[0m\n\u001b[0;32m   2855\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[0;32m   2856\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[1;32m-> 2857\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m format_table(\n\u001b[0;32m   2858\u001b[0m     pa_subtable, key, formatter\u001b[38;5;241m=\u001b[39mformatter, format_columns\u001b[38;5;241m=\u001b[39mformat_columns, output_all_columns\u001b[38;5;241m=\u001b[39moutput_all_columns\n\u001b[0;32m   2859\u001b[0m )\n\u001b[0;32m   2860\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\formatting\\formatting.py:639\u001b[0m, in \u001b[0;36mformat_table\u001b[1;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[0;32m    637\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m formatter(pa_table, query_type\u001b[38;5;241m=\u001b[39mquery_type)\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\formatting\\formatting.py:403\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[1;34m(self, pa_table, query_type)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_row(pa_table)\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\formatting\\formatting.py:444\u001b[0m, in \u001b[0;36mPythonFormatter.format_row\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyRow(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    443\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_row(pa_table)\n\u001b[1;32m--> 444\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_row(row)\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m row\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\formatting\\formatting.py:222\u001b[0m, in \u001b[0;36mPythonFeaturesDecoder.decode_row\u001b[1;34m(self, row)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, row: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mdecode_example(row) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;28;01melse\u001b[39;00m row\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\features\\features.py:2039\u001b[0m, in \u001b[0;36mFeatures.decode_example\u001b[1;34m(self, example, token_per_repo_id)\u001b[0m\n\u001b[0;32m   2024\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_example\u001b[39m(\u001b[38;5;28mself\u001b[39m, example: \u001b[38;5;28mdict\u001b[39m, token_per_repo_id: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2025\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decode example with custom feature decoding.\u001b[39;00m\n\u001b[0;32m   2026\u001b[0m \n\u001b[0;32m   2027\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2035\u001b[0m \u001b[38;5;124;03m        `dict[str, Any]`\u001b[39;00m\n\u001b[0;32m   2036\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   2038\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m-> 2039\u001b[0m         column_name: decode_nested_example(feature, value, token_per_repo_id\u001b[38;5;241m=\u001b[39mtoken_per_repo_id)\n\u001b[0;32m   2040\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[0;32m   2041\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[0;32m   2042\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m column_name, (feature, value) \u001b[38;5;129;01min\u001b[39;00m zip_dict(\n\u001b[0;32m   2043\u001b[0m             {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m example}, example\n\u001b[0;32m   2044\u001b[0m         )\n\u001b[0;32m   2045\u001b[0m     }\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\features\\features.py:1400\u001b[0m, in \u001b[0;36mdecode_nested_example\u001b[1;34m(schema, obj, token_per_repo_id)\u001b[0m\n\u001b[0;32m   1397\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (Audio, Image)):\n\u001b[0;32m   1398\u001b[0m     \u001b[38;5;66;03m# we pass the token to read and decode files from private repositories in streaming mode\u001b[39;00m\n\u001b[0;32m   1399\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m schema\u001b[38;5;241m.\u001b[39mdecode:\n\u001b[1;32m-> 1400\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m schema\u001b[38;5;241m.\u001b[39mdecode_example(obj, token_per_repo_id\u001b[38;5;241m=\u001b[39mtoken_per_repo_id)\n\u001b[0;32m   1401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\datasets\\features\\image.py:188\u001b[0m, in \u001b[0;36mImage.decode_example\u001b[1;34m(self, value, token_per_repo_id)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     image \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(BytesIO(bytes_))\n\u001b[1;32m--> 188\u001b[0m image\u001b[38;5;241m.\u001b[39mload()  \u001b[38;5;66;03m# to avoid \"Too many open files\" errors\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mgetexif()\u001b[38;5;241m.\u001b[39mget(PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mExifTags\u001b[38;5;241m.\u001b[39mBase\u001b[38;5;241m.\u001b[39mOrientation) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     image \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImageOps\u001b[38;5;241m.\u001b[39mexif_transpose(image)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\PIL\\ImageFile.py:291\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    290\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 291\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(b)\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train.evaluate(model, torch.nn.CrossEntropyLoss(), valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from ray import tune\n",
    "from ray.train import Checkpoint, get_checkpoint, report, RunConfig\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"C:\\\\Users\\\\pc\\\\Documents\\\\repos\\\\mp-2\\\\nn\\\\nn-lab2\\\\\"\n",
    "constants = {\n",
    "    \"criterion\": torch.nn.CrossEntropyLoss(),\n",
    "    \"lr\": 0.001,\n",
    "    \"n_epochs\": 40,\n",
    "    \"saving_model_path\": src_path + \"models\\\\raytune\"\n",
    "}\n",
    "config = {\n",
    "    \"batch_size\": tune.grid_search([64]),\n",
    "    \"patch_size\": tune.grid_search([256])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config, constants):\n",
    "    model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=False).to(device)\n",
    "    model.classifier[6] = torch.nn.Linear(in_features=4096, out_features=4, bias=True).to(device)\n",
    "\n",
    "    criterion = constants[\"criterion\"]\n",
    "    optimizer = optim.Adam(model.parameters(), lr=constants[\"lr\"])\n",
    "    n_epochs = constants[\"n_epochs\"]\n",
    "    saving_model_path = os.path.join(constants[\"saving_model_path\"], \n",
    "                                \"checkpoint_{kernel_size}_{fc_1_out}.model\".format(kernel_size=config[\"kernel_size\"], fc_1_out=config[\"fc_1_out\"]))\n",
    "\n",
    "    train_loader = WrappedDataLoader(DataLoader(train_dataset, batch_size=1, shuffle=True), to_device)\n",
    "    valid_loader = WrappedDataLoader(DataLoader(validation_dataset, batch_size=1, shuffle=False), to_device)\n",
    "    test_loader = WrappedDataLoader(DataLoader(test_dataset, batch_size=1, shuffle=False), to_device)\n",
    "\n",
    "    print('\\nFitting nn model')\n",
    "    start_time = time.time()\n",
    "\n",
    "    losses_arr = train.fit(n_epochs, model, criterion, optimizer, train_loader, valid_loader)\n",
    "    print(f'Fit time: {time.time() - start_time} s')\n",
    "\n",
    "    check_point = torch.load('model.pt', map_location=device)\n",
    "    model.load_state_dict(check_point)\n",
    "\n",
    "    test_loss, test_accuracy = train.evaluate(model, criterion, test_loader)\n",
    "\n",
    "    if saving_model_path is not None:\n",
    "        print('Saving model')\n",
    "        torch.save((model.state_dict(), optimizer.state_dict()), saving_model_path)\n",
    "        checkpoint = Checkpoint.from_directory(constants[\"saving_model_path\"])\n",
    "        report(\n",
    "            {\"loss\": test_loss, \"accuracy\": test_accuracy},\n",
    "            checkpoint = checkpoint\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(num_samples=2, gpus_per_trial=0.125):\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(\n",
    "            tune.with_parameters(train, constants=constants),\n",
    "            resources={\"cpu\": 0.25, \"gpu\": gpus_per_trial}\n",
    "        ),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"accuracy\",\n",
    "            mode=\"max\",\n",
    "            # scheduler=scheduler,\n",
    "            num_samples=num_samples,\n",
    "            # search_alg=ax_search\n",
    "        ),\n",
    "        param_space=config,\n",
    "        run_config=RunConfig(storage_path=os.path.join(src_path, \"raytune\"))\n",
    "    )\n",
    "    results = tuner.fit()\n",
    "    \n",
    "    best_result = results.get_best_result(\"accuracy\", \"max\")\n",
    "\n",
    "    return best_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
