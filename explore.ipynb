{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab8a174378b401ea25276dce1c0375e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e263eadb7d43fabc60a2ad9be7a0eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\pc/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Using cache found in C:\\Users\\pc/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "from data import dataset, PlantOrgansDataset\n",
    "from preprocessing import preprocess_image_and_mask\n",
    "import torchvision.transforms.v2 as T\n",
    "import torch\n",
    "import numpy as np\n",
    "from alexnet import MyTransform, SlidingWindow, get_extractor, get_feature, get_model\n",
    "from train import device, pixel_validate, patch_loss, patch_validate, evaluate, fit\n",
    "import torch.utils.data as data_utils\n",
    "from kmeans import KNN\n",
    "from evaluate import calculate_metrics\n",
    "from torch.utils.data import DataLoader\n",
    "from alexnet_knn import perform_segmentation, save_features, segmentation_image, retrieve_features, read_features, load_and_merge_knn_features\n",
    "import umap\n",
    "from sklearn.manifold import trustworthiness\n",
    "import pickle\n",
    "import os\n",
    "import lz4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonTransform = T.Compose([\n",
    "        T.Resize(size=(2048, 2048)),\n",
    "        T.ToImage()\n",
    "        \n",
    "        # T.RandomHorizontalFlip(p=0.5),\n",
    "        # T.RandomVerticalFlip(p=0.5),\n",
    "        # T.RandomRotation(degrees=45)\n",
    "    ])\n",
    "imagesTransform = T.Compose([\n",
    "    T.ToDtype(torch.float32, scale=False),\n",
    "    # T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    MyTransform(64),\n",
    "    T.Resize((224, 224)),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "masksTransform = T.Compose([\n",
    "    T.ToDtype(torch.int8, scale=False),\n",
    "    # T.Normalize(mean=[0.0014], std=[0.0031]),\n",
    "    MyTransform(64),\n",
    "    # T.Resize((224, 224))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation_data = dataset['train'].train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = PlantOrgansDataset(train_validation_data['train'], commonTransform, imagesTransform, masksTransform)\n",
    "validation_dataset = PlantOrgansDataset(train_validation_data['test'], commonTransform, imagesTransform, masksTransform)\n",
    "test_dataset = PlantOrgansDataset(dataset['validation'], commonTransform, imagesTransform, masksTransform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy_weights = torch.tensor([\n",
    "        4.8033e-04,\n",
    "        6.4129e-03,\n",
    "        3.9272e-03,\n",
    "        9.7140e-01,\n",
    "        1.7778e-02], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset:  4596\n",
      "validation_dataset:  1149\n",
      "test_dataset:  1437\n"
     ]
    }
   ],
   "source": [
    "print(\"train_dataset: \", len(train_dataset))\n",
    "print(\"validation_dataset: \", len(validation_dataset))\n",
    "print(\"test_dataset: \", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedDataLoader:\n",
    "    def __init__(self, loader, func):\n",
    "        self.loader = loader\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.loader)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in iter(self.loader):\n",
    "            batch_cuda = []\n",
    "            for X, y in batch:\n",
    "                batch_cuda.append(self.func(X, y))\n",
    "            yield batch_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(X: torch.Tensor, y: torch.Tensor):\n",
    "    return X.to(device, dtype=torch.float32), y.to(device, dtype=torch.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    batchs_amount = len(batch)\n",
    "    current_images = []\n",
    "    current_masks = []\n",
    "    current_length = 0\n",
    "    i = 0\n",
    "    while i < batchs_amount or current_length >= batch_size:\n",
    "        if current_length == batch_size:\n",
    "            if len(current_images) == 1:\n",
    "                result_images = current_images[0]\n",
    "                result_masks = current_masks[0]\n",
    "            else:\n",
    "                result_images = torch.concatenate(current_images)\n",
    "                result_masks = torch.concatenate(current_masks)\n",
    "            current_images = []\n",
    "            current_masks = []\n",
    "            current_length = 0\n",
    "            yield result_images, result_masks\n",
    "        elif current_length > batch_size:\n",
    "            concatenated_images = torch.concatenate(current_images)\n",
    "            concatenated_masks = torch.concatenate(current_masks)\n",
    "            images_split = torch.split(concatenated_images, batch_size, dim=0)\n",
    "            masks_split = torch.split(concatenated_masks, batch_size, dim=0)\n",
    "            current_images = [images_split[len(images_split) - 1]]\n",
    "            current_masks = [masks_split[len(masks_split) - 1]]\n",
    "            current_length = len(current_images[0])\n",
    "            for j in range(len(images_split) - 1):\n",
    "                yield images_split[j], masks_split[j]\n",
    "        else:  \n",
    "            images, masks = batch[i]\n",
    "            i += 1\n",
    "            current_length += len(images)\n",
    "            current_images.append(images)\n",
    "            current_masks.append(masks)\n",
    "    if current_length > 0:\n",
    "        concatenated_images = torch.concatenate(current_images)\n",
    "        concatenated_masks = torch.concatenate(current_masks)\n",
    "        yield concatenated_images, concatenated_masks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = WrappedDataLoader(\n",
    "    DataLoader(train_dataset, batch_size=1, shuffle=False, collate_fn=custom_collate_fn, \n",
    "               pin_memory=True, pin_memory_device=[device]), to_device)\n",
    "valid_loader = WrappedDataLoader(\n",
    "    DataLoader(validation_dataset, batch_size=1, shuffle=False, collate_fn=custom_collate_fn,\n",
    "               pin_memory=False, pin_memory_device=[device]), to_device)\n",
    "test_loader = WrappedDataLoader(\n",
    "    DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=custom_collate_fn,\n",
    "               pin_memory=False, pin_memory_device=[device]), to_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"C:\\\\Users\\\\pc\\\\Documents\\\\repos\\\\mp-2\\\\nn\\\\nn-lab2\\\\\"\n",
    "\n",
    "constants = {\n",
    "    \"criterion\": torch.nn.CrossEntropyLoss(),\n",
    "    \"lr\": 0.0001,\n",
    "    \"n_epochs\": 40,\n",
    "    \"saving_model_path\": src_path + \"models\\\\raytune\"\n",
    "}\n",
    "config = {\n",
    "    # \"batch_size\": tune.grid_search([64*64]),\n",
    "    # \"patch_size\": tune.grid_search([32])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "image_to_tensor = T.Compose([\n",
    "    # T.ToImage(),\n",
    "    T.ToDtype(dtype=torch.float32, scale=True),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    T.Resize(size=(2048, 2048)),\n",
    "])\n",
    "mask_to_tensor = T.Compose([\n",
    "    T.ToImage(),\n",
    "    T.ToDtype(dtype=torch.float32, scale=False)\n",
    "])\n",
    "mask_of_uniform_size = T.Compose([\n",
    "    T.Resize((2048, 2048), interpolation=T.InterpolationMode.NEAREST_EXACT),\n",
    "    mask_to_tensor,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = train_validation_data['train'][1]['image']\n",
    "# X = image_to_tensor(image).unsqueeze(0).to(device)\n",
    "# y = mask_of_uniform_size(train_validation_data['train'][1]['label']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T.Resize((224, 224))(train_validation_data['train'][1]['image'])\n",
    "# T.Resize((224, 224))(mask_to_image(train_validation_data['train'][1]['label']))\n",
    "\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "# get_graph_node_names(model)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# import torch\n",
    "# import gc\n",
    "# objects = []\n",
    "# for obj in gc.get_objects():\n",
    "#     try:\n",
    "#         if (torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data))) and obj.is_cuda:\n",
    "#             objects.append((type(obj), obj.size(), obj.numel()))\n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "# sorted_by_size = sorted(objects, key=lambda tup: tup[2], reverse=True)\n",
    "# sorted_by_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_classes = perform_segmentation(X, y.unsqueeze(0))\n",
    "# segmentation_image(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del X, y\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segmentation_image(mask_to_tensor(train_validation_data['train'][1]['label'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = train_validation_data['train'][1]['image']\n",
    "# X = image_to_tensor(image).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tqdm\n",
    "# for i in tqdm.tqdm(range(100)):\n",
    "#     image = train_validation_data['train'][i]['image']\n",
    "#     features = retrieve_features(image_to_tensor(image).unsqueeze(0).to(device))\n",
    "#     save_features(i, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_features(index, src_path, layer_name=\"classifier.0\", sliding_window_size=32, \n",
    "                         sliding_window_step=11):\n",
    "    file_name = os.path.join(src_path, \"features\", \n",
    "                            \"train_{layer_name}_{window_size}_{window_step}_{i}.lz4\"\n",
    "                              .format(layer_name=layer_name, window_size=sliding_window_size, window_step=sliding_window_step, i=index)\n",
    "                            )\n",
    "    with lz4.frame.open(file_name, mode=\"rb\") as f:\n",
    "      features_shape = pickle.load(f)\n",
    "      features = pickle.load(f)\n",
    "      return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"umap_model_5.lz4\"), 'rb') as f:\n",
    "    reducer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducer = umap.UMAP(n_neighbors=30, n_components=64, low_memory=True)\n",
    "# features_to_train_reducer = load_and_merge_knn_features(\"cpu\", src_path, indices=range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_truths_to_train_reducer = get_ground_truth_for_indices(range(5), dataset_tag='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_truths_to_train_reducer = ground_truths_to_train_reducer.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducer.fit(features_to_train_reducer, ground_truths_to_train_reducer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = os.path.join(\"f:\\d\", \"umap_model_5.lz4\")\n",
    "# with open(file_name, mode=\"wb\") as f:\n",
    "#       pickle.dump(reducer, f, protocol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transformed_features(src_path, file_name):\n",
    "    with lz4.frame.open(os.path.join(src_path, \"features\", file_name), mode=\"rb\") as f:\n",
    "        _ = pickle.load(f)\n",
    "        loaded_f = pickle.load(f)\n",
    "    return loaded_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    }
   ],
   "source": [
    "test_features = load_transformed_features(src_path, \"10_test_reduced_5.lz4\")\n",
    "train_features_10 = load_transformed_features(src_path, \"10_train_reduced_5.lz4\")\n",
    "train_features_15 = load_transformed_features(src_path, \"15_train_reduced_5.lz4\")\n",
    "train_features_25 = load_transformed_features(src_path, \"25_train_reduced_5.lz4\")\n",
    "train_features_30 = load_transformed_features(src_path, \"30_train_reduced_5.lz4\")\n",
    "train_features_35 = load_transformed_features(src_path, \"35_train_reduced_5.lz4\")\n",
    "train_features_40 = load_transformed_features(src_path, \"40_train_reduced_5.lz4\")\n",
    "train_features_45 = load_transformed_features(src_path, \"45_train_reduced_5.lz4\")\n",
    "train_features_50 = load_transformed_features(src_path, \"50_train_reduced_5.lz4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = torch.concat([train_features_10, train_features_15, train_features_25, train_features_30, train_features_35, train_features_40, train_features_45, train_features_50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_transformed = reducer.transform(features)\n",
    "# features_transformed_ = torch.tensor(features_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    }
   ],
   "source": [
    "test_feature_1 = load_and_merge_knn_features(\"cpu\", src_path, indices=range(1, 2), reducer=reducer, name=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = os.path.join(src_path, \"features\", \"45_train_reduced_5.lz4\")\n",
    "# with lz4.frame.open(file_name, mode=\"wb\") as f:\n",
    "#       pickle.dump(features.shape , f) \n",
    "#       pickle.dump(features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truths = get_ground_truth_for_indices(range(50), dataset_tag='train')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([34969, 64])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_features = load_and_merge_knn_features()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN(train_features, ground_truths.to(device), 5, save_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pictures = test_feature_1.view(1, 187, 187, -1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_four = T.Compose([\n",
    "    T.Resize((47, 47), interpolation=T.InterpolationMode.NEAREST)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([47, 47, 64])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_picture = resize_four(test_pictures[0].permute(2, 0, 1)).permute(1, 2, 0)\n",
    "torch.cuda.empty_cache()\n",
    "test_picture.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "predicted_mask = torch.zeros((test_picture.size(0), test_picture.size(1)))\n",
    "for i in range(0, test_picture.size(0), 24):\n",
    "    i_upper_limit = min(i+24, test_picture.size(1))\n",
    "    predicted_classes = knn.predict(test_picture[i : i_upper_limit].view(-1, 64))\n",
    "    torch.cuda.empty_cache()\n",
    "    predicted_mask[i : i_upper_limit] = predicted_classes.view(-1, test_picture.size(1)).to(\"cpu\")\n",
    "    print(i)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=224x224>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_mask = get_ground_truth_for_indices(range(1, 2), dataset_tag='test')\n",
    "segmentation_image(mask_to_tensor(ground_truth_mask.view(-1, 187, 187)[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 47, 47])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_to_tensor(predicted_mask).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=224x224>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentation_image(mask_to_tensor(predicted_mask)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = os.path.join(src_path, \"features\", \"predicted_mask_validate_half_1.lz4\")\n",
    "with lz4.frame.open(file_name, mode=\"wb\") as f:\n",
    "      pickle.dump(predicted_mask, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_mask.view(-1, 187, 187)[0]\n",
    "predicted_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics(device, ground_truth_mask.view(-1, 187, 187)[0].to(torch.long), predicted_mask.to(torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "from torchmetrics.segmentation import MeanIoU\n",
    "mask_to_tensor = T.Compose([\n",
    "    T.ToImage(),\n",
    "    T.ToDtype(torch.float32, scale=False),\n",
    "])\n",
    "predicted_mask_ =  predicted_mask.to(torch.long).unsqueeze(0).to(device)\n",
    "ground_truth_transform = T.Compose([\n",
    "    T.Resize(size=(predicted_mask_.to(torch.long).size(1),  predicted_mask_.to(torch.long).size(2)), interpolation=T.InterpolationMode.NEAREST_EXACT),\n",
    "    T.ToDtype(dtype=torch.int64)\n",
    "])\n",
    "ground_truth = ground_truth_transform(mask_to_tensor(ground_truth_mask.view(-1, 187, 187)[0].to(torch.long))).to(device=device)\n",
    "acc = torchmetrics.functional.accuracy( predicted_mask_.to(torch.long), ground_truth, task=\"multiclass\", num_classes=5)\n",
    "meanIoU = MeanIoU(num_classes=5, input_format='index', include_background=False, per_class=True).to(device)\n",
    "meanIoU_result = meanIoU( predicted_mask_.to(torch.long), ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'meanIoU_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m meanIoU_result\n",
      "\u001b[1;31mNameError\u001b[0m: name 'meanIoU_result' is not defined"
     ]
    }
   ],
   "source": [
    "meanIoU_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2303, device='cuda:0')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_features[0] - train_features[1]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
